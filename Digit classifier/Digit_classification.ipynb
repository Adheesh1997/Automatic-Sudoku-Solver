{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FTXZ7Ep0fgy"
      },
      "source": [
        "# Build model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiPycgUf0uIQ"
      },
      "source": [
        "## import liraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gn_KxGDM0w3s",
        "outputId": "639c3590-3f37-4a10-c5c9-6f58adce1af3"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Dense, Flatten, BatchNormalization, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from pathlib import Path\n",
        "from PIL import Image \n",
        "from keras import models\n",
        "import os,random\n",
        "\n",
        "print(\"Libraries imported\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Libraries imported\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZbcaqyH0bOO"
      },
      "source": [
        "## Load data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WeD2nqC0PhU"
      },
      "source": [
        "dataPath = \"/content/drive/MyDrive/Academic/7th Sem/Computer Vision/Mini project/data set/Digits\"\n",
        "\n",
        "data = os.listdir(dataPath)\n",
        "dataX = []\n",
        "dataY = []\n",
        "\n",
        "dataClasses = len(data)\n",
        "\n",
        "for i in range (1,dataClasses):\n",
        "  data_list = os.listdir(dataPath +\"/\"+str(i))\n",
        "  for j in data_list:\n",
        "    pic = cv2.imread(dataPath +\"/\"+str(i)+\"/\"+j)\n",
        "    pic = cv2.resize(pic,(28,28))\n",
        "    dataX.append(pic)\n",
        "    dataY.append(i)\n",
        "\n",
        "dataX = np.array(dataX)\n",
        "dataY = np.array(dataY)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRly2mPr2Dex"
      },
      "source": [
        "## split data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANGSZqSC2LGf",
        "outputId": "71fcccef-0a7a-49b7-d790-ed671fc3d377"
      },
      "source": [
        "trainX, testX, trainY, testY = train_test_split(dataX,dataY,test_size=0.1)\n",
        "trainX, validX, trainY, validY = train_test_split(trainX,trainY,test_size=0.2)\n",
        "print(\"Training Set Shape = \",trainX.shape)\n",
        "print(\"Validation Set Shape = \",validX.shape)\n",
        "print(\"Test Set Shape = \",testX.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Set Shape =  (3076, 28, 28, 3)\n",
            "Validation Set Shape =  (770, 28, 28, 3)\n",
            "Test Set Shape =  (428, 28, 28, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZNnVT1x2wIQ"
      },
      "source": [
        "## preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8vF75B52yX4"
      },
      "source": [
        "def Prep(img):\n",
        "  #making image grayscale\n",
        "  img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) \n",
        "\n",
        "  #Histogram equalization to enhance contrast\n",
        "  img = cv2.equalizeHist(img) \n",
        "  img = img/255 #normalizing\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpmYaPFL3TJw"
      },
      "source": [
        "trainX = np.array(list(map(Prep, trainX)))\n",
        "testX = np.array(list(map(Prep, testX)))\n",
        "validX= np.array(list(map(Prep, validX)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoROLRBP3xfJ"
      },
      "source": [
        "## Reshape images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM6VclSS30RS"
      },
      "source": [
        "trainX = trainX.reshape(trainX.shape[0], trainX.shape[1], trainX.shape[2],1)\n",
        "testX = testX.reshape(testX.shape[0], testX.shape[1], testX.shape[2],1)\n",
        "validX = validX.reshape(validX.shape[0], validX.shape[1], validX.shape[2],1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqvdTmWF4H7Y"
      },
      "source": [
        "## Augment data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH5kGUwZ4KqI"
      },
      "source": [
        "datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.2, shear_range=0.1, rotation_range=10)\n",
        "datagen.fit(trainX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "froG1XXk4UVI"
      },
      "source": [
        "## generate labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHi7O2YG4W1I"
      },
      "source": [
        "trainY = to_categorical(trainY, dataClasses)\n",
        "testY = to_categorical(testY, dataClasses)\n",
        "validY = to_categorical(validY, dataClasses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jV65yABd4wAa"
      },
      "source": [
        "## NN (Dense net) model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5MEXTDz4yB8"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add((Conv2D(60,(5,5),input_shape=(32, 32, 1) ,padding = 'Same' ,activation='relu')))\n",
        "model.add((Conv2D(60, (5,5),padding=\"same\",activation='relu')))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add((Conv2D(30, (3,3),padding=\"same\", activation='relu')))\n",
        "model.add((Conv2D(30, (3,3), padding=\"same\", activation='relu')))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "optimizer = RMSprop(learning_rate=0.005, rho=0.9, epsilon = 1e-08, decay=0.0)\n",
        "model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "#Fit the model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFFnnHzI5m-x"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PviSjDIE5pEw",
        "outputId": "4a6b280b-a6d7-4d59-c6f4-7d0098210d00"
      },
      "source": [
        "history = model.fit(datagen.flow(trainX, trainY, batch_size=100),\n",
        "                              epochs = 30, validation_data = (validX, validY),\n",
        "                              verbose = 2)\n",
        "score = model.evaluate(testX, testY, verbose=0)\n",
        "print('Test Score = ',score[0])\n",
        "print('Test Accuracy =', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "39/39 - 60s - loss: 0.2958 - accuracy: 0.9039 - val_loss: 0.0425 - val_accuracy: 0.9843\n",
            "Epoch 2/30\n",
            "39/39 - 61s - loss: 0.2251 - accuracy: 0.9304 - val_loss: 0.0563 - val_accuracy: 0.9790\n",
            "Epoch 3/30\n",
            "39/39 - 61s - loss: 0.2207 - accuracy: 0.9343 - val_loss: 0.0256 - val_accuracy: 0.9906\n",
            "Epoch 4/30\n",
            "39/39 - 61s - loss: 0.2584 - accuracy: 0.9367 - val_loss: 0.0998 - val_accuracy: 0.9622\n",
            "Epoch 5/30\n",
            "39/39 - 61s - loss: 0.1158 - accuracy: 0.9638 - val_loss: 0.0494 - val_accuracy: 0.9822\n",
            "Epoch 6/30\n",
            "39/39 - 61s - loss: 0.1944 - accuracy: 0.9527 - val_loss: 0.0183 - val_accuracy: 0.9927\n",
            "Epoch 7/30\n",
            "39/39 - 61s - loss: 0.1174 - accuracy: 0.9735 - val_loss: 0.0231 - val_accuracy: 0.9916\n",
            "Epoch 8/30\n",
            "39/39 - 61s - loss: 0.1190 - accuracy: 0.9698 - val_loss: 0.0416 - val_accuracy: 0.9916\n",
            "Epoch 9/30\n",
            "39/39 - 61s - loss: 0.1177 - accuracy: 0.9730 - val_loss: 0.0229 - val_accuracy: 0.9916\n",
            "Epoch 10/30\n",
            "39/39 - 61s - loss: 0.0976 - accuracy: 0.9737 - val_loss: 0.0178 - val_accuracy: 0.9937\n",
            "Epoch 11/30\n",
            "39/39 - 61s - loss: 0.1051 - accuracy: 0.9695 - val_loss: 0.0210 - val_accuracy: 0.9927\n",
            "Epoch 12/30\n",
            "39/39 - 61s - loss: 0.0809 - accuracy: 0.9795 - val_loss: 0.0167 - val_accuracy: 0.9948\n",
            "Epoch 13/30\n",
            "39/39 - 60s - loss: 0.1346 - accuracy: 0.9719 - val_loss: 0.0104 - val_accuracy: 0.9958\n",
            "Epoch 14/30\n",
            "39/39 - 60s - loss: 0.1257 - accuracy: 0.9722 - val_loss: 0.0135 - val_accuracy: 0.9958\n",
            "Epoch 15/30\n",
            "39/39 - 61s - loss: 0.0927 - accuracy: 0.9758 - val_loss: 0.0090 - val_accuracy: 0.9969\n",
            "Epoch 16/30\n",
            "39/39 - 60s - loss: 0.1062 - accuracy: 0.9745 - val_loss: 0.0607 - val_accuracy: 0.9874\n",
            "Epoch 17/30\n",
            "39/39 - 60s - loss: 0.1030 - accuracy: 0.9748 - val_loss: 0.0138 - val_accuracy: 0.9937\n",
            "Epoch 18/30\n",
            "39/39 - 60s - loss: 0.1015 - accuracy: 0.9751 - val_loss: 0.0095 - val_accuracy: 0.9969\n",
            "Epoch 19/30\n",
            "39/39 - 60s - loss: 0.0730 - accuracy: 0.9827 - val_loss: 0.0079 - val_accuracy: 0.9979\n",
            "Epoch 20/30\n",
            "39/39 - 60s - loss: 0.1635 - accuracy: 0.9664 - val_loss: 0.0082 - val_accuracy: 0.9969\n",
            "Epoch 21/30\n",
            "39/39 - 60s - loss: 0.0940 - accuracy: 0.9779 - val_loss: 0.0085 - val_accuracy: 0.9979\n",
            "Epoch 22/30\n",
            "39/39 - 60s - loss: 0.0654 - accuracy: 0.9848 - val_loss: 0.0105 - val_accuracy: 0.9979\n",
            "Epoch 23/30\n",
            "39/39 - 61s - loss: 0.0795 - accuracy: 0.9824 - val_loss: 0.0118 - val_accuracy: 0.9958\n",
            "Epoch 24/30\n",
            "39/39 - 60s - loss: 0.1256 - accuracy: 0.9800 - val_loss: 0.0129 - val_accuracy: 0.9969\n",
            "Epoch 25/30\n",
            "39/39 - 61s - loss: 0.0921 - accuracy: 0.9814 - val_loss: 0.0182 - val_accuracy: 0.9969\n",
            "Epoch 26/30\n",
            "39/39 - 60s - loss: 0.0885 - accuracy: 0.9787 - val_loss: 0.0329 - val_accuracy: 0.9927\n",
            "Epoch 27/30\n",
            "39/39 - 60s - loss: 0.0661 - accuracy: 0.9858 - val_loss: 0.0048 - val_accuracy: 0.9990\n",
            "Epoch 28/30\n",
            "39/39 - 60s - loss: 0.0672 - accuracy: 0.9824 - val_loss: 0.0042 - val_accuracy: 0.9990\n",
            "Epoch 29/30\n",
            "39/39 - 60s - loss: 0.0927 - accuracy: 0.9798 - val_loss: 0.0072 - val_accuracy: 0.9979\n",
            "Epoch 30/30\n",
            "39/39 - 60s - loss: 0.0820 - accuracy: 0.9827 - val_loss: 0.0100 - val_accuracy: 0.9958\n",
            "Test Score =  0.01177910901606083\n",
            "Test Accuracy = 0.992438554763794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMFxni4n-9yB"
      },
      "source": [
        "# save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7x95-3Z-_W4",
        "outputId": "bb69f3b3-1782-4285-aafd-ac082c1339b9"
      },
      "source": [
        "# Save model in h5 format\n",
        "\n",
        "model.save(\"/content/drive/MyDrive/Academic/7th Sem/Computer Vision/Mini project/model for digits/digit_classifier.h5\")\n",
        "print(\"Saved H5 model to drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved H5 model to drive\n",
            "Saved H5 model to drive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}